
kernel void cnsUpdate2D(const dlong Nelements,
                            const dfloat dt,  
                            const dfloat rka,
                            const dfloat rkb,
                            const dfloat * restrict rhsq,
                            dfloat * restrict resq,
                            dfloat * restrict q){
  
  // Low storage Runge Kutta time step update
  for(dlong e=0;e<Nelements;++e;outer0){

    for(int n=0;n<p_Np;++n;inner0){

      for(int fld=0; fld< p_Nfields; ++fld){

        const dlong id = e*p_Np*p_Nfields + fld*p_Np + n;
        
        dfloat r_resq = resq[id];
        dfloat r_rhsq = rhsq[id]; 
        dfloat r_q    = q[id];

        r_resq = rka*r_resq + dt*r_rhsq;
        r_q   += rkb*r_resq;
        
        resq[id] = r_resq;
        q[id]    = r_q;
      }
    }
  }
}


kernel void cnsRkStage2D(const dlong Nelements,
                         const int rk,
                         const dfloat dt,  
                         const dfloat * restrict rkA,
                         const dfloat * restrict q,
                         const dfloat * restrict rkrhsq,
                               dfloat * restrict rkq){
  
  // Runge Kutta intermediate stage
  for(dlong e=0;e<Nelements;++e;outer0){\
    for(int n=0;n<p_Np;++n;inner0){

      for(int fld=0; fld< p_Nfields; ++fld){
        const dlong id = e*p_Np*p_Nfields + fld*p_Np + n;
        
        dfloat r_q = q[id];

        for (int i=0;i<rk;i++) {
          const dlong offset = Nelements*p_Nfields*p_Np;
          r_q += dt*rkA[7*rk + i]*rkrhsq[id+i*offset];
        }
        
        rkq[id] = r_q;
      }
    }
  }
}

kernel void cnsRkUpdate2D(const dlong Nelements,
                          const int rk,
                          const dfloat dt,  
                          const dfloat * restrict rkA,
                          const dfloat * restrict rkE,
                          const dfloat * restrict q,
                          const dfloat * restrict rhsq,
                                dfloat * restrict rkrhsq,
                                dfloat * restrict rkq,
                                dfloat * restrict rkerr){
  
  // Runge Kutta intermediate stage
  for(dlong e=0;e<Nelements;++e;outer0){\
    for(int n=0;n<p_Np;++n;inner0){

      for(int fld=0; fld< p_Nfields; ++fld){
        const dlong id = e*p_Np*p_Nfields + fld*p_Np + n;
        const dlong offset = Nelements*p_Nfields*p_Np;
  
        dfloat r_rhsq = rhsq[id];

        if (rk==6) { //last stage
          dfloat r_q = q[id];
          dfloat r_rkerr = 0.;
          for (int i=0;i<6;i++) {
            r_q     += dt*rkA[7*rk + i]*rkrhsq[id+i*offset];
            r_rkerr += dt*rkE[       i]*rkrhsq[id+i*offset];
          }
          r_q     += dt*rkA[7*rk + 6]*r_rhsq;
          r_rkerr += dt*rkE[       6]*r_rhsq;

          rkq[id] = r_q;
          rkerr[id] = r_rkerr;
        }

        rkrhsq[id+rk*offset] = r_rhsq;
      }
    }
  }
}

kernel void cnsErrorEstimate2D(const dlong N,
                               const dfloat ATOL,
                               const dfloat RTOL,
                               const dfloat * restrict q,
                               const dfloat * restrict rkq,
                               const dfloat * restrict rkerr,
                                     dfloat * restrict errtmp){
  
  for(dlong b=0;b<(N+p_blockSize-1)/p_blockSize;++b;outer0){
    
    volatile shared dfloat s_err[p_blockSize];

    for(int t=0;t<p_blockSize;++t;inner0){
      const dlong id = t + p_blockSize*b;
      if (id<N) {
        const dfloat   qn =   q[id];
        const dfloat rkqn = rkq[id];
        const dfloat qmax = (qn>rkqn) ? qn : rkqn;
        dfloat sk = ATOL + RTOL*qmax;

        s_err[t] = (rkerr[id]/sk)*(rkerr[id]/sk);
      } else {
        s_err[t] = 0.f;  
      }
    }

    barrier(localMemFence);
#if p_blockSize>512
    for(int t=0;t<p_blockSize;++t;inner0) if(t<512) s_err[t] += s_err[t+512];
    barrier(localMemFence);
#endif
#if p_blockSize>256
    for(int t=0;t<p_blockSize;++t;inner0) if(t<256) s_err[t] += s_err[t+256];
    barrier(localMemFence);
#endif

    for(int t=0;t<p_blockSize;++t;inner0) if(t<128) s_err[t] += s_err[t+128];
    barrier(localMemFence);

    for(int t=0;t<p_blockSize;++t;inner0) if(t< 64) s_err[t] += s_err[t+64];
    barrier(localMemFence);

    for(int t=0;t<p_blockSize;++t;inner0) if(t< 32) s_err[t] += s_err[t+32];
    for(int t=0;t<p_blockSize;++t;inner0) if(t< 16) s_err[t] += s_err[t+16];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  8) s_err[t] += s_err[t+8];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  4) s_err[t] += s_err[t+4];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  2) s_err[t] += s_err[t+2];

    for(int t=0;t<p_blockSize;++t;inner0) if(t<  1) errtmp[b] = s_err[0] + s_err[1];
  }
}
