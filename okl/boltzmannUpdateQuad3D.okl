kernel void boltzmannDOPRIrkStageQuad3D(const iint Nelements,
					const iint rk,
					const dfloat dt,  
					const dfloat * restrict rkA,
					const dfloat * restrict q,
					const dfloat * restrict rkrhsq,
					      dfloat * restrict rkq){
  
  // Runge Kutta intermediate stage
  for(iint e=0;e<Nelements;++e;outer0){
    for(iint n=0;n<p_Np;++n;inner0){

      for(int fld=0; fld< p_Nfields; ++fld){
        const iint id = e*p_Np*p_Nfields + fld*p_Np + n;
        
        dfloat r_q = q[id];
	
	for (int i=0;i<rk;i++) {
          const iint offset = Nelements*p_Nfields*p_Np;
          r_q += dt*rkA[7*rk + i]*rkrhsq[id+i*offset];
        }
        
        rkq[id] = r_q;
      }
    }
  }
}

kernel void boltzmannDOPRIUpdateQuad3D(const iint Nelements,
					 const iint rk,
					 const dfloat dt,  
					 const dfloat * restrict rka,
					 const dfloat * restrict rkb,
					 const dfloat * restrict q,
					 const dfloat * restrict rhsq,
					 const dfloat * restrict qCorr,
					       dfloat * restrict rkrhsq,
					       dfloat * restrict rkq,
					       dfloat * restrict rkerr){
  
  // Runge Kutta intermediate stage
  for(iint e=0;e<Nelements;++e;outer0){
    for(iint n=0;n<p_Np;++n;inner0){
      
      for(iint fld=0; fld < p_Nfields; ++fld){
        const iint id = e*p_Np*p_Nfields + fld*p_Np + n;
        const iint offset = Nelements*p_Nfields*p_Np;
  
        dfloat r_rhsq = rhsq[id]+qCorr[id];

        if (rk==6) { //last stage
          dfloat r_q = q[id];
          dfloat r_rkerr = 0.;
          for (int i=0;i<6;i++) {
            r_q     += dt*rka[7*rk + i]*rkrhsq[id+i*offset];
            r_rkerr += dt*rkb[       i]*rkrhsq[id+i*offset];
          }
          r_q     += dt*rka[7*rk + 6]*r_rhsq;
          r_rkerr += dt*rkb[       6]*r_rhsq;

          rkq[id] = r_q;
          rkerr[id] = r_rkerr;
        }

        rkrhsq[id+rk*offset] = r_rhsq;
      }
    }
  }
}

kernel void boltzmannDOPRIerrorEstimateQuad3D(const iint N,
					      const dfloat absTol,
					      const dfloat relTol,
					      const dfloat * restrict vgeo,
					      const dfloat * restrict q,
					      const dfloat * restrict rkq,
					      const dfloat * restrict rkerr,
					            dfloat * restrict errtmp){
  
  for(iint b=0;b<(N+p_blockSize-1)/p_blockSize;++b;outer0){
    
    volatile shared dfloat s_err[p_blockSize];

    for(int t=0;t<p_blockSize;++t;inner0){
      const iint id = t + p_blockSize*b;

      //construct Jacobian ID
      const iint e = id/(p_Nfields*p_Np);
      const iint n = id%p_Np;
      const iint jid = e*p_Nvgeo*p_Np + 10*p_Np + n;
      
      if (id<N) {
	const dfloat    J = vgeo[jid];
        const dfloat   qn =   q[id];
        const dfloat rkqn = rkq[id];
        const dfloat qmax = (qn>rkqn) ? qn : rkqn;
        dfloat sk = absTol + relTol*qmax;

        s_err[t] = J*(rkerr[id]/sk)*(rkerr[id]/sk);
      } else {
        s_err[t] = 0.f;
      }
    }

    barrier(localMemFence);
#if p_blockSize>512
    for(int t=0;t<p_blockSize;++t;inner0) if(t<512) s_err[t] += s_err[t+512];
    barrier(localMemFence);
#endif
#if p_blockSize>256
    for(int t=0;t<p_blockSize;++t;inner0) if(t<256) s_err[t] += s_err[t+256];
    barrier(localMemFence);
#endif

    for(int t=0;t<p_blockSize;++t;inner0) if(t<128) s_err[t] += s_err[t+128];
    barrier(localMemFence);

    for(int t=0;t<p_blockSize;++t;inner0) if(t< 64) s_err[t] += s_err[t+64];
    barrier(localMemFence);

    for(int t=0;t<p_blockSize;++t;inner0) if(t< 32) s_err[t] += s_err[t+32];
    for(int t=0;t<p_blockSize;++t;inner0) if(t< 16) s_err[t] += s_err[t+16];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  8) s_err[t] += s_err[t+8];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  4) s_err[t] += s_err[t+4];
    for(int t=0;t<p_blockSize;++t;inner0) if(t<  2) s_err[t] += s_err[t+2];

    for(int t=0;t<p_blockSize;++t;inner0) if(t<  1) errtmp[b] = s_err[0] + s_err[1];
  }
}

kernel void boltzmannLSERKbasicUpdateQuad3D(const iint Nelements,
					   const dfloat dt,
					   const dfloat rka,
					   const dfloat rkb,
					    const dfloat * restrict vgeo,
					   const dfloat * restrict rhsq,
					   const dfloat * restrict qCorr,
					   dfloat * restrict resq,
					   dfloat * restrict q){
  
  // Low storage Runge Kutta time step update
  for(iint e=0;e<Nelements;++e;outer0){

    for(iint n=0;n<p_Np;++n;inner0){
      
      for(iint fld=0; fld<p_Nfields; ++fld){
	
	const iint id = e*p_Np*p_Nfields + fld*p_Np + n;
	
	dfloat r_resq = resq[id];
	dfloat r_rhsq = rhsq[id] + qCorr[id]; 
	dfloat r_q = q[id];
	
	r_resq = rka*r_resq + dt*(r_rhsq);
	r_q   += rkb*r_resq;
	
	resq[id] = r_resq;

	q[id] = r_q;
      }
    }
  }
}



kernel void boltzmannLSERKUpdateQuad3D(const iint Nelements,
				       const iint * restrict elementIDs,
				       const iint saved,
				       const dfloat dt,
				       const dfloat rka,
				       const dfloat rkb,
				       const iint shift,
				       const dfloat * restrict rhsq,
				       dfloat * restrict qpop,
				       const dfloat * restrict qCorr,
				       dfloat * restrict resq,
				       dfloat * restrict qpre){
  
  // Low storage Runge Kutta time step update
  for(iint es=0;es<Nelements;++es;outer0){

    exclusive iint e;
    
    for(iint n=0;n<p_Np;++n;inner0){

      e = elementIDs[es];
      
      for(iint fld=0; fld<p_Nfields; ++fld){

	const iint id = e*p_Np*p_Nfields + fld*p_Np + n;
	
	dfloat r_resq = resq[id];
	dfloat r_rhsq = rhsq[id]; 
	dfloat r_q = qpre[id];
	
	r_resq = rka*r_resq + dt*(r_rhsq + qCorr[id]);
	r_q   += rkb*r_resq;
	if (saved)
	  qpop[e*p_Np*p_Nfields*p_nrhs + shift*p_Np*p_Nfields + fld*p_Np + n] = r_rhsq;
	
	resq[id] = r_resq;

	qpre[id] = r_q;
      }
    }
  }
}


kernel void boltzmannLSERKTraceUpdateQuad3D(const iint Nelements,
					    const iint * restrict vmapM,
					    dfloat * restrict fQM,
					    dfloat * restrict qpre,
					    dfloat * restrict q){

  for (iint e = 0; e < Nelements; ++e; outer0) {
    for(iint n=0;n<p_Np;++n;inner0){
      for (iint fld = 0; fld < p_Nfields; ++fld) {
	const iint id = e*p_Np*p_Nfields + fld*p_Np + n;
	q[id] = qpre[id];
	fQM[id] = qpre[id];
      }
    }
  }
}

					    

kernel void boltzmannMRSAAB3UpdateQuad3D(const iint Nelements,
					const iint * restrict elementIds,
					const dfloat expdt,
					const dfloat ab1,
					const dfloat ab2,
					const dfloat ab3,
					const dfloat saab1,
					const dfloat saab2,
					const dfloat saab3,
					const iint   shift,
					const dfloat * restrict rhsq,
					dfloat * restrict fQM,
					dfloat * restrict qCorr,
					dfloat * restrict q){

  // Low storage Runge Kutta time step update
  for(iint es=0;es<Nelements;++es;outer0){
    
    shared dfloat s_q[p_Np*p_Nfields];
    exclusive iint e;
    for(iint n=0;n<p_Np;++n;inner0){
      e  = elementIds[es];
      
      const iint id = n + e*p_Np*p_Nfields;
      const iint rid = n + e*p_Np*p_Nfields*3;
      
      // hard-coded for 3th order
      const iint rhsId1 = rid + ((shift+0)%3)*p_Nfields*p_Np;
      const iint rhsId2 = rid + ((shift+1)%3)*p_Nfields*p_Np;
      const iint rhsId3 = rid + ((shift+2)%3)*p_Nfields*p_Np;
      
      for(iint fld=0; fld< p_Nfields; ++fld){
	
	//load q and update
	if(fld<4)
	  s_q[n+fld*p_Np] = q[id+fld*p_Np] + ab1*rhsq[rhsId1+fld*p_Np]+ab2*rhsq[rhsId2+fld*p_Np]+ab3*rhsq[rhsId3+fld*p_Np];
	else
	  s_q[n+fld*p_Np] = expdt*q[id+fld*p_Np] + saab1*(rhsq[rhsId1+fld*p_Np] + qCorr[rhsId1+fld*p_Np]) + saab2*(rhsq[rhsId2+fld*p_Np] + qCorr[rhsId2+fld*p_Np]) + saab3*(rhsq[rhsId3+fld*p_Np] + qCorr[rhsId3+fld*p_Np]);
      }
    }
    // make sure all node data is loaded into shared
    barrier(localMemFence);
    for(iint n=0;n<p_Np;++n;inner0){

        const iint id = p_Nfields*e*p_Np + n;

        for (iint fld = 0; fld < p_Nfields; ++fld){
	  q[id+fld*p_Np]     = s_q[n+fld*p_Np];
	  fQM[id+fld*p_Np]   = s_q[n+fld*p_Np];
	}
    }

  }
}
  

kernel void boltzmannMRSAAB3TraceUpdateQuad3D(const iint Nelements,
					     const iint * restrict elementIds,
					     const dfloat expdt,
					     const dfloat ab1,
					     const dfloat ab2,
					     const dfloat ab3,
					     const dfloat saab1,
					     const dfloat saab2,
					     const dfloat saab3,
					     const iint   shift,
					     const dfloat * restrict rhsq,
					     dfloat * restrict fQM,
					     dfloat * restrict qCorr,
					     dfloat * restrict q){
  
  // Low storage Runge Kutta time step update
  for(iint es=0;es<Nelements;++es;outer0){
    
    shared dfloat s_q[p_Np*p_Nfields];
    exclusive iint e;
    for(iint n=0;n<p_Np;++n;inner0){
      e  = elementIds[es];

      const iint id = n + e*p_Np*p_Nfields;
      const iint rid = n + e*p_Np*p_Nfields*3;
      
      // hard-coded for 3th order
      const iint rhsId1 = rid + ((shift+0)%3)*p_Nfields*p_Np;
      const iint rhsId2 = rid + ((shift+1)%3)*p_Nfields*p_Np;
      const iint rhsId3 = rid + ((shift+2)%3)*p_Nfields*p_Np;
      
      for(iint fld=0; fld< p_Nfields; ++fld){
	
	//load q and update
	if(fld<4)
	  s_q[n+fld*p_Np] = q[id+fld*p_Np] + ab1*rhsq[rhsId1+fld*p_Np]+ab2*rhsq[rhsId2+fld*p_Np]+ab3*rhsq[rhsId3+fld*p_Np];
	else
	  s_q[n+fld*p_Np] = expdt*q[id+fld*p_Np] + saab1*(rhsq[rhsId1+fld*p_Np] + qCorr[rhsId1+fld*p_Np]) + saab2*(rhsq[rhsId2+fld*p_Np] + qCorr[rhsId2+fld*p_Np]) + saab3*(rhsq[rhsId3+fld*p_Np] + qCorr[rhsId3+fld*p_Np]);
      }
    }
    // make sure all node data is loaded into shared
    barrier(localMemFence);
    for(iint n=0;n<p_Np;++n;inner0){
      const iint id = p_Nfields*e*p_Np + n;

      for (iint fld = 0; fld < p_Nfields; ++fld){
	fQM[id+fld*p_Np]   = s_q[n+fld*p_Np];
      }
    }
  }
}

kernel void boltzmannMRSAAB4UpdateQuad3D(const iint Nelements,
					 const iint * restrict elementIds,
					 const dfloat expdt,
					 const dfloat ab1,
					 const dfloat ab2,
					 const dfloat ab3,
					 const dfloat ab4,
					 const dfloat saab1,
					 const dfloat saab2,
					 const dfloat saab3,
					 const dfloat saab4,
					 const iint   shift,
					 const dfloat * restrict rhsq,
					 dfloat * restrict fQM,
					 dfloat * restrict qCorr,
					 dfloat * restrict q){
  
  // Low storage Runge Kutta time step update
  for(iint es=0;es<Nelements;++es;outer0){
    
    shared dfloat s_q[p_Np*p_Nfields];
    exclusive iint e;
    for(iint n=0;n<p_Np;++n;inner0){
      e  = elementIds[es];

      const iint id = n + e*p_Np*p_Nfields;
      const iint rid = n + e*p_Np*p_Nfields*4;
      
      // hard-coded for 3th order
      const iint rhsId1 = rid + ((shift+0)%4)*p_Nfields*p_Np;
      const iint rhsId2 = rid + ((shift+1)%4)*p_Nfields*p_Np;
      const iint rhsId3 = rid + ((shift+2)%4)*p_Nfields*p_Np;
      const iint rhsId4 = rid + ((shift+3)%4)*p_Nfields*p_Np;
      
      for(iint fld=0; fld< p_Nfields; ++fld){
	
	//load q and update
	if(fld<4)
	  s_q[n+fld*p_Np] = q[id+fld*p_Np] + ab1*rhsq[rhsId1+fld*p_Np]+ab2*rhsq[rhsId2+fld*p_Np]+ab3*rhsq[rhsId3+fld*p_Np] + ab4*rhsq[rhsId4+fld*p_Np];
	else
	  s_q[n+fld*p_Np] = expdt*q[id+fld*p_Np] + saab1*(rhsq[rhsId1+fld*p_Np] + qCorr[rhsId1+fld*p_Np]) + saab2*(rhsq[rhsId2+fld*p_Np] + qCorr[rhsId2+fld*p_Np]) + saab3*(rhsq[rhsId3+fld*p_Np] + qCorr[rhsId3+fld*p_Np]) + saab4*(rhsq[rhsId4+fld*p_Np] + qCorr[rhsId4 + fld*p_Np]);
      }
    }
    // make sure all node data is loaded into shared
    barrier(localMemFence);
    for(iint n=0;n<p_Np;++n;inner0){
      const iint id = p_Nfields*e*p_Np + n;

      for (iint fld = 0; fld < p_Nfields; ++fld){
	q[id+fld*p_Np]     = s_q[n+fld*p_Np];
	fQM[id+fld*p_Np]     = s_q[n+fld*p_Np];
      }
    }

  }
}
  

kernel void boltzmannMRSAAB4TraceUpdateQuad3D(const iint Nelements,
					     const iint * restrict elementIds,
					     const dfloat expdt,
					     const dfloat ab1,
					     const dfloat ab2,
					     const dfloat ab3,
					      const dfloat ab4,
					     const dfloat saab1,
					     const dfloat saab2,
					     const dfloat saab3,
					      const dfloat saab4,
					     const iint   shift,
					     const dfloat * restrict rhsq,
					     dfloat * restrict fQM,
					      dfloat * restrict filterCopy,
					     dfloat * restrict qCorr,
					     dfloat * restrict q){
  
  // Low storage Runge Kutta time step update
  for(iint es=0;es<Nelements;++es;outer0){
    
    shared dfloat s_q[p_Np*p_Nfields];
    exclusive iint e;
    for(iint n=0;n<p_Np;++n;inner0){
      e  = elementIds[es];

      const iint id = n + e*p_Np*p_Nfields;
      const iint rid = n + e*p_Np*p_Nfields*4;
      
      // hard-coded for 4th order
      const iint rhsId1 = rid + ((shift+0)%4)*p_Nfields*p_Np;
      const iint rhsId2 = rid + ((shift+1)%4)*p_Nfields*p_Np;
      const iint rhsId3 = rid + ((shift+2)%4)*p_Nfields*p_Np;
      const iint rhsId4 = rid + ((shift+3)%4)*p_Nfields*p_Np;
      
      for(iint fld=0; fld< p_Nfields; ++fld){
	
	//load q and update
	if(fld<4)
	  s_q[n+fld*p_Np] = q[id+fld*p_Np] + ab1*rhsq[rhsId1+fld*p_Np]+ab2*rhsq[rhsId2+fld*p_Np]+ab3*rhsq[rhsId3+fld*p_Np] + ab4*rhsq[rhsId4+fld*p_Np];
	else
	  s_q[n+fld*p_Np] = expdt*q[id+fld*p_Np] + saab1*(rhsq[rhsId1+fld*p_Np] + qCorr[rhsId1+fld*p_Np]) + saab2*(rhsq[rhsId2+fld*p_Np] + qCorr[rhsId2+fld*p_Np]) + saab3*(rhsq[rhsId3+fld*p_Np] + qCorr[rhsId3+fld*p_Np]) + saab4*(rhsq[rhsId4+fld*p_Np] + qCorr[rhsId4+fld*p_Np]);
      }
    }
    // make sure all node data is loaded into shared
    barrier(localMemFence);
    for(iint n=0;n<p_Np;++n;inner0){
      const iint id = p_Nfields*e*p_Np + n;

      for (iint fld = 0; fld < p_Nfields; ++fld){
	fQM[id+fld*p_Np]   = s_q[n+fld*p_Np];
	//make sure boundary data is available in second filter step
	filterCopy[id+fld*p_Np]   = s_q[n+fld*p_Np]; 
      }
    }
  }
}
